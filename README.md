## MarkovProcesses 

The program shall implement the value iteration algorithm for finding the optimal policy 
for each state of an MDP using Bellmanâ€™s equation. After each of the first 20 iterations 
of the value iteration algorithm,your program should print to stdout the J value and the 
optimal policy for each state of the given MDP.

Jason John 
JJJ170000
CS 4375 HW1 Part 2

## platform
Java

## what to work on
Nothing to improve

## instructions on use
For running in the terminal, you will need to first type the command "javac CS4375A3P1.java"

Then you will need to type the command "java CS4375A3P1" and enter 4 paramters after that commanded, each followed by a space.

The previous command will be immediately followed by the numerical number of states, then number of actions, then name of file, then numerical value of decay.
For example, type "java CS4375A3P1 4 2 a3train.dat .9" and enter

Example files are added to the repository
